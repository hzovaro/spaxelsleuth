{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different storage methods \n",
    "---\n",
    "See if there's a better way to read/write the data in different formats.\n",
    "Want to \n",
    "1) speed up read/write time \n",
    "2) find a way to store metadata in the file without having to save as columns\n",
    "3) save disk space (compression?)\n",
    "\n",
    "\n",
    "Try/investigate:\n",
    "- pytables\n",
    "- sqlite\n",
    "- parquet\n",
    "- apache arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: saving data plus metadata to the same .hdf file \n",
    "# Some dummy data\n",
    "N = 1_000_000\n",
    "data = np.random.normal(size=(N, 100))\n",
    "df_data = pd.DataFrame(data=data, index=list(range(data.shape[0])))\n",
    "\n",
    "# Metadata \n",
    "metadata = {\n",
    "    \"Setting 1\": \"foo\",\n",
    "    \"Setting 2\": \"bar\",\n",
    "    \"Setting 3\": 100,\n",
    "    \"Setting 4\": \"foo\",\n",
    "    \"Setting 5\": \"bar\",\n",
    "    \"Setting 6\": 100,\n",
    "    \"Setting 7\": \"positive\",\n",
    "    \"Setting 8\": \"m\",\n",
    "    \"Setting 9\": -99999,\n",
    "    \"Setting 10\": \"foo\",\n",
    "    \"Setting 11\": \"bar\",\n",
    "    \"Setting 12\": 100,\n",
    "    \"Setting 13\": \"foo\",\n",
    "    \"Setting 14\": \"bar\",\n",
    "    \"Setting 15\": 3.4235423,\n",
    "}\n",
    "df_metadata = pd.DataFrame(metadata.items(), columns=[\"Setting\", \"Value\"])\n",
    "\n",
    "df_all = df_data.copy()\n",
    "for key in metadata.keys():\n",
    "    df_all[key] = metadata[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'hdf_test_file_old.hd5': No such file or directory\n",
      "<magic-timeit>:5: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->axis0] [items->None]\n",
      "\n",
      "<magic-timeit>:5: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block0_items] [items->None]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "fname_old = \"hdf_test_file_old.hd5\"\n",
    "os.system(f\"rm {fname_old}\")\n",
    "\n",
    "# Method 1: merge DataFrames, save whole thing to single file \n",
    "df_all.to_hdf(fname_old, mode=\"w\", key=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<magic-timeit>:6: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block0_values] [items->Index(['Setting', 'Value'], dtype='object')]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 ms ± 13.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "fname_new = \"hdf_test_file_new.hd5\"\n",
    "os.system(f\"rm {fname_new}\")\n",
    "\n",
    "# Save to file \n",
    "df_data.to_hdf(fname_new, mode=\"w\", key=\"data\")\n",
    "df_metadata.to_hdf(fname_new, mode=\"r+\", key=\"metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 ms ± 12 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "fname_new_attrs = \"hdf_test_file_new_attrs.hd5\"\n",
    "os.system(f\"rm {fname_new_attrs}\")\n",
    "\n",
    "# Save to file \n",
    "store = pd.HDFStore(fname_new_attrs)\n",
    "store.put(\"data\", df_data)\n",
    "store.get_storer(\"data\").attrs.metadata = metadata\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.99 s ± 322 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "fname_old = \"hdf_test_file_old.hd5\"\n",
    "# Load the object-type DataFrame containing the columns \n",
    "df_all_out = pd.read_hdf(fname_old, key=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<magic-timeit>:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "<magic-timeit>:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "<magic-timeit>:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "<magic-timeit>:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "<magic-timeit>:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "<magic-timeit>:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "<magic-timeit>:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.06 s ± 7.04 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<magic-timeit>:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "fname_new = \"hdf_test_file_new.hd5\"\n",
    "# Load the numerical-type DataFrame containing the columns and the metadata DataFrame separately \n",
    "df_out = pd.read_hdf(fname_new, key=\"data\")\n",
    "df_metadata_out = pd.read_hdf(fname_new, key=\"metadata\")\n",
    "df_out.metadata = df_metadata_out.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.07 s ± 18.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "fname_new_attrs = \"hdf_test_file_new_attrs.hd5\"\n",
    "with pd.HDFStore(fname_new_attrs) as store:\n",
    "    df_data_out_attrs = store[\"data\"]\n",
    "    metadata_out_attrs = store.get_storer(\"data\").attrs.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings \n",
    "---\n",
    "**Writing to disk**:\n",
    "- new method is much faster - saving an object-type DataFrame is very slow.\n",
    "\n",
    "**Reading from disk**:\n",
    "- new method is similarly much faster (by a factor of ~2) even when adding the metadata dictionary back to the DataFrame as an attribute, i.e.  \n",
    "```\n",
    "df_all.metadata = metadata\n",
    "```\n",
    "**Disk space**:\n",
    "- new method: 772 MB\n",
    "- old method: 845 MB\n",
    "\n",
    "**Takeaway**: \n",
    "- Try using the .attrs property of a HDFStore. With this, we can store metadata directly paired with the data on-disk - much better than assuming metadata, e.g. settings, etc. at runtime and then manually adding them back in. We can still add the metadata as columns at runtime as we've been doing up until now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.08 s ± 10.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# How fast is it to just read the metadata?\n",
    "fname_new_attrs = \"hdf_test_file_new_attrs.hd5\"\n",
    "with pd.HDFStore(fname_new_attrs) as store:\n",
    "    df_data_out_attrs = store[\"data\"]\n",
    "    metadata_out_attrs = store.get_storer(\"data\").attrs.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.29 ms ± 446 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Just reading the metadata\n",
    "fname_new_attrs = \"hdf_test_file_new_attrs.hd5\"\n",
    "with pd.HDFStore(fname_new_attrs) as store:\n",
    "    metadata_out_attrs = store.get_storer(\"data\").attrs.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What columns in the main SAMI DataFrame could be transferred to a metadata dictionary?\n",
    "---\n",
    "i.e., what columns contain only 1 unique value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default config file\n",
      "Loading user config file\n"
     ]
    }
   ],
   "source": [
    "from spaxelsleuth import load_user_config\n",
    "try:\n",
    "    load_user_config(\"/Users/u5708159/Desktop/spaxelsleuth_test/.myconfig.json\")\n",
    "except FileNotFoundError:\n",
    "    load_user_config(\"/home/u5708159/.spaxelsleuthconfig.json\")\n",
    "from spaxelsleuth.io.io import load_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sami.py (1507) load_sami_df(): INFO: Loading DataFrame from file /Users/u5708159/Desktop/spaxelsleuth_test/output/sami_default_recom-comp_extcorr_minSNR=5_minANR=3.hd5 [last modified 2023-09-16 10:53:52.805085]...\n",
      "sami.py (1535) load_sami_df(): INFO: finished!\n"
     ]
    }
   ],
   "source": [
    "# Load the DataFrame\n",
    "df = load_df(ncomponents=\"recom\",\n",
    "                bin_type=\"default\",\n",
    "                eline_SNR_min=5,\n",
    "                eline_ANR_min=3,\n",
    "                correct_extinction=True,\n",
    "                debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galaxy centre x0_px (projected, arcsec)\n",
      "Galaxy centre y0_px (projected, arcsec)\n",
      "Bin size (pixels)\n",
      "Bin size (square arcsec)\n",
      "Median SNR (B, full field)\n",
      "Median SNR (R, full field)\n",
      "Median SNR (B, 1R_e)\n",
      "Median SNR (R, 1R_e)\n",
      "Median SNR (B, 1.5R_e)\n",
      "Median SNR (R, 1.5R_e)\n",
      "Median SNR (B, 2R_e)\n",
      "Median SNR (R, 2R_e)\n",
      "Bad class #\n",
      "Cluster member\n",
      "r/R_200\n",
      "v/sigma_cluster\n",
      "Good?\n",
      "Missing flux flag - HALPHA (component 1)\n",
      "Missing flux flag - HALPHA (component 2)\n",
      "Missing flux flag - HALPHA (component 3)\n",
      "Missing flux flag - HALPHA (total)\n",
      "Low amplitude flag - HBETA (total)\n",
      "Low amplitude flag - NII6583 (total)\n",
      "Low amplitude flag - OI6300 (total)\n",
      "Low amplitude flag - OII3726+OII3729 (total)\n",
      "Low amplitude flag - OIII5007 (total)\n",
      "Low amplitude flag - SII6716 (total)\n",
      "Low amplitude flag - SII6731 (total)\n",
      "Missing flux flag - SII6731 (total)\n",
      "Extinction correction applied\n",
      "log SFR (component 2)\n",
      "log SFR error (lower) (component 2)\n",
      "log SFR error (upper) (component 2)\n",
      "log SFR (component 3)\n",
      "log SFR error (lower) (component 3)\n",
      "log SFR error (upper) (component 3)\n",
      "log SFR surface density (component 2)\n",
      "log SFR surface density error (lower) (component 2)\n",
      "log SFR surface density error (upper) (component 2)\n",
      "log SFR surface density (component 3)\n",
      "log SFR surface density error (lower) (component 3)\n",
      "log SFR surface density error (upper) (component 3)\n",
      "eline_SNR_min\n",
      "sigma_gas_SNR_min\n",
      "eline_ANR_min\n",
      "line_flux_SNR_cut\n",
      "missing_fluxes_cut\n",
      "line_amplitude_SNR_cut\n",
      "flux_fraction_cut\n",
      "vgrad_cut\n",
      "sigma_gas_SNR_cut\n",
      "stekin_cut\n",
      "survey\n",
      "as_per_px\n",
      "N_x\n",
      "N_y\n",
      "x0_px\n",
      "y0_px\n",
      "ncomponents\n",
      "bin_type\n",
      "__use_lzifu_fits\n",
      "__lzifu_ncomponents\n",
      "debug\n",
      "flux units\n",
      "continuum units\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    if len(df[c].unique()) == 1:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: df.shape = (3409, 413)\n",
      "After: df_trimmed.shape = (3409, 384)\n"
     ]
    }
   ],
   "source": [
    "metadata_cols = [\n",
    "    \"Galaxy centre x0_px (projected, arcsec)\",\n",
    "    \"Galaxy centre y0_px (projected, arcsec)\",\n",
    "    \"Bad class #\",\n",
    "    \"Good?\",\n",
    "    \"correct_extinction\",\n",
    "    \"eline_SNR_min\",\n",
    "    \"sigma_gas_SNR_min\",\n",
    "    \"eline_ANR_min\",\n",
    "    \"line_flux_SNR_cut\",\n",
    "    \"missing_fluxes_cut\",\n",
    "    \"line_amplitude_SNR_cut\",\n",
    "    \"flux_fraction_cut\",\n",
    "    \"vgrad_cut\",\n",
    "    \"sigma_gas_SNR_cut\",\n",
    "    \"stekin_cut\",\n",
    "    \"survey\",\n",
    "    \"as_per_px\",\n",
    "    \"N_x\",\n",
    "    \"N_y\",\n",
    "    \"x0_px\",\n",
    "    \"y0_px\",\n",
    "    \"ncomponents\",\n",
    "    \"bin_type\",\n",
    "    \"__use_lzifu_fits\",\n",
    "    \"__lzifu_ncomponents\",\n",
    "    \"debug\",\n",
    "    \"flux units\",\n",
    "    \"continuum units\",\n",
    "]\n",
    "metadata_dict = dict(zip(metadata_cols, [df[c].unique()[0] for c in metadata_cols]))\n",
    "df_trimmed = df.copy()\n",
    "df_trimmed = df_trimmed.drop(columns=metadata_cols)\n",
    "print(f\"Before: df.shape = {df.shape}\")\n",
    "print(f\"After: df_trimmed.shape = {df_trimmed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory saved by dropping metadata columns: 1.650 MB\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "print(f\"Memory saved by dropping metadata columns: {(sys.getsizeof(df) - sys.getsizeof(df_trimmed)) / 1064 / 1064:.3f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spaxelsleuth.config import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'as_per_px': 0.5,\n",
       " 'N_x': 50,\n",
       " 'N_y': 50,\n",
       " 'x0_px': 24.5,\n",
       " 'y0_px': 24.5,\n",
       " 'sigma_inst_kms': 29.6,\n",
       " 'eline_list': ['HALPHA',\n",
       "  'HBETA',\n",
       "  'NII6583',\n",
       "  'OI6300',\n",
       "  'OII3726+OII3729',\n",
       "  'OIII5007',\n",
       "  'SII6716',\n",
       "  'SII6731'],\n",
       " 'bin_types': ['default', 'adaptive', 'sectors'],\n",
       " 'data_cube_path': '/Users/u5708159/Desktop/spaxelsleuth_test/sami/dr3',\n",
       " 'input_path': '/Users/u5708159/Desktop/spaxelsleuth_test/sami/dr3',\n",
       " 'output_path': '/Users/u5708159/Desktop/spaxelsleuth_test/output',\n",
       " 'lzifu_products_path': 'sami/lzifu/products/'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings[\"sami\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spaxelsleuth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
